{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"store_urls.pkl\", 'rb') as f:\n",
    "    urls = pickle.load(f)\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(urls)):\n",
    "    if urls[i] == None:\n",
    "        urls.pop(i)\n",
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeThread(threading.Thread):\n",
    "    def __init__(self, url, j):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.url = url\n",
    "        self.j = j\n",
    "\n",
    "    def run(self):\n",
    "        driver = webdriver.Chrome()\n",
    "        try:\n",
    "            driver.get(self.url)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            # Find the article tag\n",
    "            article = soup.find('article')\n",
    "\n",
    "            # Find all p and header (h1 to h6) tags inside the article tag\n",
    "            if article:\n",
    "                elements = article.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "                # Collect the text content of each element in the correct order\n",
    "                full_text = [element.text.strip() for element in elements]\n",
    "                full_text = \"\\n\".join(full_text)\n",
    "\n",
    "                # Join the collected text into a single string with newlines\n",
    "                if full_text.strip():\n",
    "                    print(\"Text extracted.\")\n",
    "                    with open(f'C:\\\\Users\\\\Ajay Kanna\\\\Desktop\\\\UGRC\\\\extract abstract\\\\Lancet\\\\full_text_stored\\\\extracted_text_{self.j}.txt', 'w', encoding='utf-8') as file:\n",
    "                        file.write(full_text)\n",
    "            else:\n",
    "                print(\"No article tag found\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "threads = []\n",
    "batch = 5\n",
    "for i in range(0, len(urls), 4):\n",
    "    for url in urls[i: i+4]:\n",
    "        t = ScrapeThread(url, )\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Python312\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ajay Kanna\\AppData\\Local\\Temp\\ipykernel_104444\\1056820090.py\", line 62, in run\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n",
      "NameError: name 'driver' is not defined. Did you mean: 'webdriver'?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread initialized\n",
      "Thread running\n",
      "Thread 0 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 1 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 2 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 3 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 4 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 5 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 6 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 7 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 8 started\n",
      "Thread initialized\n",
      "Thread running\n",
      "Thread 9 started\n",
      "Queueing URL 1\n",
      "Queue size is now: 1\n",
      "Queueing URL 2\n",
      "Queue size is now: 2\n",
      "Queueing URL 3\n",
      "Queue size is now: 3\n",
      "Queueing URL 4\n",
      "Queue size is now: 4\n",
      "Queueing URL 5\n",
      "Queue size is now: 5\n",
      "Queueing URL 6\n",
      "Queue size is now: 6\n",
      "Queueing URL 7\n",
      "Queue size is now: 7\n",
      "Queueing URL 8\n",
      "Queue size is now: 8\n",
      "Queueing URL 9\n",
      "Queue size is now: 9\n",
      "Queueing URL 10\n",
      "Queue size is now: 10\n",
      "Queueing URL 11\n",
      "Error processing URL 1: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 2: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 3: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 4: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 5: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 6: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 7: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 8: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 9: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n",
      "Error processing URL 10: name 'driver' is not defined\n",
      "Releasing semaphore and marking task done\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import Queue\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "class ScrapeThread(threading.Thread):\n",
    "    def __init__(self, queue, semaphore):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.semaphore = semaphore\n",
    "        print(\"Thread initialized\")\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            print(\"Thread running\")\n",
    "            decision = False\n",
    "            url, j = self.queue.get()\n",
    "            if url is None:\n",
    "                break\n",
    "\n",
    "            '''chrome_options = Options()\n",
    "            chrome_options.add_argument('--headless')\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "            chrome_service = Service('chromedriver.exe')  # Path to chromedriver\n",
    "            driver = webdriver.Chrome(service=chrome_service, options=chrome_options)'''\n",
    "\n",
    "            driver = webdriver.Chrome()\n",
    "            try:\n",
    "                driver.get(url)\n",
    "                time.sleep(4)\n",
    "                \n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "                # Find the article tag\n",
    "                article = soup.find('article')\n",
    "\n",
    "                # Find all p and header (h1 to h6) tags inside the article tag\n",
    "                if article:\n",
    "                    elements = article.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "                    # Collect the text content of each element in the correct order\n",
    "                    full_text = [element.text.strip() for element in elements]\n",
    "                    full_text = \"\\n\".join(full_text)\n",
    "\n",
    "                    full_text = filter_text(full_text)\n",
    "\n",
    "                    # Join the collected text into a single string with newlines\n",
    "                    if full_text.strip():\n",
    "                        print(f\"Text extracted for URL {j}.\")\n",
    "                        with open(f'C:\\\\Users\\\\Ajay Kanna\\\\Desktop\\\\UGRC\\\\extract abstract\\\\Lancet\\\\full_text_stored\\\\extracted_text_{j}.txt', 'w', encoding='utf-8') as file:\n",
    "                            file.write(full_text)\n",
    "                else:\n",
    "                    print(f\"No article tag found for URL {j}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing URL {j}: {e}\")\n",
    "                \n",
    "            finally:\n",
    "                print(\"Releasing semaphore and marking task done\")\n",
    "                driver.quit()\n",
    "                self.queue.task_done()\n",
    "                self.semaphore.release()\n",
    "\n",
    "\n",
    "def filter_text(text):\n",
    "    # Remove references like (6) or [6] or References (6)\n",
    "    text = re.sub(r'\\bReferences? \\(\\d+\\)', '', text)\n",
    "    text = re.sub(r'\\bReferences\\b', '', text)\n",
    "    # Remove \"Cited by\" with any number\n",
    "    text = re.sub(r'\\bCited by \\(\\d+\\)', '', text)\n",
    "    text = re.sub(r'\\bCited by \\d+', '', text)\n",
    "    text = re.sub(r'\\bCited by\\b', '', text)\n",
    "\n",
    "    if len(text.split()) < 50:\n",
    "        text = \"\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def main(urls):\n",
    "    queue = Queue()\n",
    "    semaphore = threading.Semaphore(10)  # Limit the number of concurrent threads to 4\n",
    "\n",
    "    threads = []\n",
    "    for i in range(10):\n",
    "        t = ScrapeThread(queue, semaphore)\n",
    "        t.start()\n",
    "        print(f\"Thread {i} started\")\n",
    "        threads.append(t)\n",
    "\n",
    "    for j, url in enumerate(urls, start=1):\n",
    "        print(f\"Queueing URL {j}\")\n",
    "        semaphore.acquire()\n",
    "        queue.put((url, j))\n",
    "        print(f\"Queue size is now: {queue.qsize()}\")\n",
    "\n",
    "    queue.join()\n",
    "    print(\"All tasks have been processed\")\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "        print(\"Sending stop signal to threads\")\n",
    "        queue.put(None)\n",
    "    for t in threads:\n",
    "        print(\"Waiting for thread to finish\")\n",
    "        t.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
