{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 1915, Total count: 169\n",
      "Year: 1916, Total count: 177\n",
      "Year: 1917, Total count: 169\n",
      "Year: 1918, Total count: 92\n",
      "Year: 1919, Total count: 106\n",
      "Year: 1920, Total count: 139\n",
      "Year: 1921, Total count: 81\n",
      "Year: 1922, Total count: 98\n",
      "Year: 1923, Total count: 111\n",
      "Year: 1924, Total count: 123\n",
      "Year: 1925, Total count: 195\n",
      "Year: 1926, Total count: 173\n",
      "Year: 1927, Total count: 201\n",
      "Year: 1928, Total count: 210\n",
      "Year: 1929, Total count: 192\n",
      "Year: 1930, Total count: 151\n",
      "Year: 1931, Total count: 141\n",
      "Year: 1932, Total count: 148\n",
      "Year: 1933, Total count: 198\n",
      "Year: 1934, Total count: 153\n",
      "Year: 1935, Total count: 150\n",
      "Year: 1936, Total count: 147\n",
      "Year: 1937, Total count: 134\n",
      "Year: 1938, Total count: 118\n",
      "Year: 1939, Total count: 142\n",
      "Year: 1940, Total count: 142\n",
      "Year: 1941, Total count: 128\n",
      "Year: 1942, Total count: 115\n",
      "Year: 1943, Total count: 80\n",
      "Year: 1944, Total count: 79\n",
      "Year: 1945, Total count: 83\n",
      "Year: 1946, Total count: 71\n",
      "Year: 1947, Total count: 83\n",
      "Year: 1948, Total count: 110\n",
      "Year: 1949, Total count: 129\n",
      "Year: 1950, Total count: 125\n",
      "Year: 1951, Total count: 157\n",
      "Year: 1952, Total count: 184\n",
      "Year: 1953, Total count: 199\n",
      "Year: 1954, Total count: 206\n",
      "Year: 1955, Total count: 206\n",
      "Year: 1956, Total count: 191\n",
      "Year: 1957, Total count: 171\n",
      "Year: 1958, Total count: 206\n",
      "Year: 1959, Total count: 234\n",
      "Year: 1960, Total count: 238\n",
      "Year: 1961, Total count: 289\n",
      "Year: 1962, Total count: 354\n",
      "Year: 1963, Total count: 361\n",
      "Year: 1964, Total count: 472\n",
      "Year: 1965, Total count: 542\n",
      "Year: 1966, Total count: 549\n",
      "Year: 1967, Total count: 643\n",
      "Year: 1968, Total count: 641\n",
      "Year: 1969, Total count: 600\n",
      "Year: 1970, Total count: 632\n",
      "Year: 1971, Total count: 723\n",
      "Year: 1972, Total count: 851\n",
      "Year: 1973, Total count: 847\n",
      "Year: 1974, Total count: 1098\n",
      "Year: 1975, Total count: 1107\n",
      "Year: 1976, Total count: 1010\n",
      "Year: 1977, Total count: 1248\n",
      "Year: 1978, Total count: 1357\n",
      "Year: 1979, Total count: 1424\n",
      "Year: 1980, Total count: 1612\n",
      "Year: 1981, Total count: 1670\n",
      "Year: 1982, Total count: 1672\n",
      "Year: 1983, Total count: 1618\n",
      "Year: 1984, Total count: 1695\n",
      "Year: 1985, Total count: 1848\n",
      "Year: 1986, Total count: 2047\n",
      "Year: 1987, Total count: 1916\n",
      "Year: 1988, Total count: 2035\n",
      "Year: 1989, Total count: 2095\n",
      "Year: 1990, Total count: 2077\n",
      "Year: 1991, Total count: 2392\n",
      "Year: 1992, Total count: 2514\n",
      "Year: 1993, Total count: 2484\n",
      "Year: 1994, Total count: 2681\n",
      "Year: 1995, Total count: 2551\n",
      "Year: 1996, Total count: 2820\n",
      "Year: 1997, Total count: 2681\n",
      "Year: 1998, Total count: 2821\n",
      "Year: 1999, Total count: 2762\n",
      "Year: 2000, Total count: 2655\n",
      "Year: 2001, Total count: 2812\n",
      "Year: 2002, Total count: 3113\n",
      "Year: 2003, Total count: 2963\n",
      "Year: 2004, Total count: 3331\n",
      "Year: 2005, Total count: 3447\n",
      "Year: 2006, Total count: 3594\n",
      "Year: 2007, Total count: 3720\n",
      "Year: 2008, Total count: 3832\n",
      "Year: 2009, Total count: 4278\n",
      "Year: 2010, Total count: 4280\n",
      "Year: 2011, Total count: 4111\n",
      "Year: 2012, Total count: 4389\n",
      "Year: 2013, Total count: 4619\n",
      "Year: 2014, Total count: 4258\n",
      "Year: 2015, Total count: 4154\n",
      "Year: 2016, Total count: 3939\n",
      "Year: 2017, Total count: 4024\n",
      "Year: 2018, Total count: 4069\n",
      "Year: 2019, Total count: 4150\n",
      "Year: 2020, Total count: 4375\n",
      "Year: 2021, Total count: 4220\n",
      "Year: 2022, Total count: 3960\n",
      "Year: 2023, Total count: 3682\n",
      "Year: 2024, Total count: 1753\n",
      "Total PMIDs fetched: 159322\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "import time\n",
    "\n",
    "# Set your email here\n",
    "Entrez.email = \"relaxchumma@gmail.com\"\n",
    "\n",
    "def fetch_pmids(journal_name, retmax, year):\n",
    "    # E-utilities search query\n",
    "    search_query = f'\"{journal_name}\"[Journal] AND (\"{year}\"[Date - Publication])'\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=search_query, retmax=retmax)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record['IdList'], int(record['Count'])\n",
    "\n",
    "def fetch_all_pmids(journal_name):\n",
    "    pmids = []\n",
    "    retmax = 10000  # Number of results to fetch at a time\n",
    "    for year in range(1915, 2025):\n",
    "        pmid_list, total_count = fetch_pmids(journal_name, retmax, year)\n",
    "        print(f\"Year: {year}, Total count: {total_count}\")\n",
    "        pmids.extend(pmid_list)\n",
    "        time.sleep(0.5)  # To avoid hitting the server too hard\n",
    "    return pmids\n",
    "\n",
    "total_pmid = fetch_all_pmids(\"Proceedings of the National Academy of Sciences of the United States of America\")\n",
    "print(f\"Total PMIDs fetched: {len(total_pmid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156367\n"
     ]
    }
   ],
   "source": [
    "uniques = set(total_pmid)\n",
    "uniques = list(uniques)\n",
    "print(len(uniques))\n",
    "\n",
    "import pickle\n",
    "with open(\"store_uniques.pkl\", 'wb') as f:\n",
    "    pickle.dump(uniques, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156367\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"store_uniques.pkl\", 'rb') as f:\n",
    "    uniques = pickle.load(f)\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15067124\n"
     ]
    }
   ],
   "source": [
    "print(uniques[77910])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def check_pmc_ids(pm_ids):\n",
    "    Entrez.email = \"relaxchumma@gmail.com\"\n",
    "    \n",
    "    # Join the PubMed IDs into a single comma-separated string\n",
    "    ids_str = ','.join(pm_ids)\n",
    "    \n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=ids_str, rettype=\"full\", retmode=\"xml\")\n",
    "    xml_data = handle.read()\n",
    "    handle.close()\n",
    "    root = ET.fromstring(xml_data)\n",
    "    \n",
    "    pmc_dict = {}\n",
    "    \n",
    "    for article in root.findall(\".//PubmedArticle\"):\n",
    "        pmid = article.find(\".//PMID\").text\n",
    "        pmc_id = None\n",
    "        for article_id in article.findall(\".//ArticleId\"):\n",
    "            if article_id.attrib.get(\"IdType\") == \"pmc\":\n",
    "                pmc_id = article_id.text\n",
    "                break\n",
    "        pmc_dict[pmid] = pmc_id is not None\n",
    "    \n",
    "    return pmc_dict\n",
    "\n",
    "# Batching the PubMed IDs for efficient fetching\n",
    "batch_size = 50\n",
    "for i in range(77910, len(uniques), batch_size):\n",
    "    pmid_batch = uniques[i:i + batch_size]\n",
    "    pmc_dict = check_pmc_ids(pmid_batch)\n",
    "    \n",
    "    for pmid, is_pmc in pmc_dict.items():\n",
    "        if is_pmc:\n",
    "            with open(\"pmc_1.txt\", 'a') as f:\n",
    "                f.write(f'{pmid}\\n')\n",
    "        else:\n",
    "            with open(\"non_pmc_1.txt\", 'a') as f:\n",
    "                f.write(f'{pmid}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['38830090', '38857386', '17668480', '38865269', '9499217', '38861602', '38857388', '38843253', '38857403', '38838020', '38833466', '38830098', '8633090', '38830103', '38843184', '20987695', '38861608', '38830112', '38865272', '38857394', '38857390', '38861601', '38830100', '38857397', '38838019', '38838011', '38857392', '38833470', '38861604', '38861594', '38781227', '38833465', '38857400', '38833468', '38865271', '38830107', '38833474', '38861599', '38838013', '34934013', '12046582', '38830095', '38830094', '38833467', '38865275', '38830109', '8992486', '38833473', '38843187', '38865261', '38833475', '38857385', '38857389', '38843252', '38830104', '38865270', '388449', '38857398', '38865274', '38857402', '38861592', '38830097', '20987694', '38865264', '18893735', '38865266', '38838018', '38833464', '38857406', '38830101', '38861605', '38861609', '38838016', '38830111', '38696717', '38833469', '38833472', '38861603', '17360540', '38814876', '38857395', '38848299', '38857407', '38857409', '38830099', '9537892', '38814875', '38843183', '38857391', '38838015', '38830091', '38865262', '20351245', '38861597', '38830089', '38861607', '18107592', '38830092', '38830110', '38857399', '38857405', '38861598', '38865263', '38848300', '38838012', '38833477', '8570594', '38843186', '38833476', '38843185', '38857393', '38857396', '18893734', '38830105', '38848301', '38838014', '38838021', '38865265', '38830108', '38861606', '38830096', '38857408', '38843251', '38830102', '38861610', '38838017', '38857387', '38865267', '38861596', '38861595', '38830093', '38865260', '38861593', '38865268', '38865276', '18890150', '38833471', '38857404', '38865277', '38861600', '38865273', '19721000', '38857401', '38830106']\n"
     ]
    }
   ],
   "source": [
    "filename = 'non_pmc_1.txt'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    pmids = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "print(pmids)\n",
    "\n",
    "import pickle\n",
    "with open(\"non_pmc.pkl\", 'wb') as f:\n",
    "    pickle.dump(pmids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['38830090', '38857386', '17668480', '38865269', '9499217', '38861602', '38857388', '38843253', '38857403', '38838020', '38833466', '38830098', '8633090', '38830103', '38843184', '20987695', '38861608', '38830112', '38865272', '38857394', '38857390', '38861601', '38830100', '38857397', '38838019', '38838011', '38857392', '38833470', '38861604', '38861594', '38781227', '38833465', '38857400', '38833468', '38865271', '38830107', '38833474', '38861599', '38838013', '34934013', '12046582', '38830095', '38830094', '38833467', '38865275', '38830109', '8992486', '38833473', '38843187', '38865261', '38833475', '38857385', '38857389', '38843252', '38830104', '38865270', '388449', '38857398', '38865274', '38857402', '38861592', '38830097', '20987694', '38865264', '18893735', '38865266', '38838018', '38833464', '38857406', '38830101', '38861605', '38861609', '38838016', '38830111', '38696717', '38833469', '38833472', '38861603', '17360540', '38814876', '38857395', '38848299', '38857407', '38857409', '38830099', '9537892', '38814875', '38843183', '38857391', '38838015', '38830091', '38865262', '20351245', '38861597', '38830089', '38861607', '18107592', '38830092', '38830110', '38857399', '38857405', '38861598', '38865263', '38848300', '38838012', '38833477', '8570594', '38843186', '38833476', '38843185', '38857393', '38857396', '18893734', '38830105', '38848301', '38838014', '38838021', '38865265', '38830108', '38861606', '38830096', '38857408', '38843251', '38830102', '38861610', '38838017', '38857387', '38865267', '38861596', '38861595', '38830093', '38865260', '38861593', '38865268', '38865276', '18890150', '38833471', '38857404', '38865277', '38861600', '38865273', '19721000', '38857401', '38830106']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"non_pmc.pkl\", 'rb') as f:\n",
    "    pmids_without_pmc = pickle.load(f)\n",
    "print(pmids_without_pmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def check_pmc_ids(pm_id):\n",
    "    Entrez.email = \"relaxchumma@gmail.com\"\n",
    "    \n",
    "    handle = Entrez.efetch(db=\"pubmed\", id = pm_id, rettype=\"full\", retmode=\"xml\")\n",
    "    xml_data = handle.read()\n",
    "    handle.close()\n",
    "    root = ET.fromstring(xml_data)\n",
    "    \n",
    "    pmc_dict = {}\n",
    "    \n",
    "    for article in root.findall(\".//PubmedArticle\"):\n",
    "        pmid = article.find(\".//PMID\").text\n",
    "        pmc_id = None\n",
    "        for article_id in article.findall(\".//ArticleId\"):\n",
    "            if article_id.attrib.get(\"IdType\") == \"pmc\":\n",
    "                pmc_id = article_id.text\n",
    "                break\n",
    "        pmc_dict[pmid] = pmc_id is not None\n",
    "    \n",
    "    return pmc_dict\n",
    "check_pmc_ids(10377390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import requests\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "\n",
    "def is_pmid_in_pmc(pmid):\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi\"\n",
    "    params = {\n",
    "        'dbfrom': 'pubmed',\n",
    "        'db': 'pmc',\n",
    "        'id': pmid,\n",
    "        'retmode': 'json'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        #print(\"entered\")\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()  # Raises a HTTPError if the response was unsuccessful\n",
    "        data = response.json()\n",
    "        linksets = data.get('linksets', [])\n",
    "        if linksets and 'linksetdbs' in linksets[0]:\n",
    "            for linksetdb in linksets[0]['linksetdbs']:\n",
    "                if linksetdb['dbto'] == 'pmc':\n",
    "                    return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "    return False\n",
    "\n",
    "def process_pmid(pmid):\n",
    "    if is_pmid_in_pmc(pmid):\n",
    "        #print(\"True\")\n",
    "        return pmid, True\n",
    "    else:\n",
    "        #print(\"False\")\n",
    "        return pmid, False\n",
    "\n",
    "def main():\n",
    "    pmc_count = 0\n",
    "    not_pmc_count = 0\n",
    "    pmids = list(uniques)  # Assuming uniques is defined elsewhere\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        #print(\"hmm\")\n",
    "        futures = [executor.submit(process_pmid, pmid) for pmid in uniques]\n",
    "        print(futures)\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            #print(\"oh\")\n",
    "            pmid, is_pmc = future.result()\n",
    "            if is_pmc:\n",
    "                pmc_count += 1\n",
    "                with open(\"pmc.txt\", 'a') as f:\n",
    "                    f.write(f'{pmid}\\n')\n",
    "            else:\n",
    "                not_pmc_count += 1\n",
    "                with open(\"non_pmc.txt\", 'a') as f:\n",
    "                    f.write(f'{pmid}\\n')\n",
    "\n",
    "    print(f\"PMC: {pmc_count}, Non-PMC: {not_pmc_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(pmids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"store_pmids.pkl\", 'wb') as f:\n",
    "    pickle.dump(pmids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('store_pmid.pkl', 'rb') as file:\n",
    "    total_pmid = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
