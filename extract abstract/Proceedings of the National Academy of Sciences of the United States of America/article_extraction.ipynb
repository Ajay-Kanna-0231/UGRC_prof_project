{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import xml.etree.ElementTree as ET\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_doi(pm_id):\n",
    "    Entrez.email = \"ae22b024@smail.iitm.ac.in\"\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=pm_id, rettype=\"full\", retmode=\"xml\")\n",
    "        xml_data = handle.read()\n",
    "        handle.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for PM ID {pm_id}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    root = ET.fromstring(xml_data)\n",
    "\n",
    "    def language_check():\n",
    "        language_tag = root.find('.//Language')\n",
    "        if language_tag is not None and language_tag.text is not None:\n",
    "            if language_tag.text == \"eng\":\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        return True    # might become a problem in future\n",
    "    \n",
    "    doi_found = None\n",
    "    for eloc in root.findall('.//ELocationID'):\n",
    "        if eloc.get('EIdType') == 'doi':\n",
    "            doi_found = eloc.text.strip()\n",
    "            break\n",
    "    \n",
    "    if doi_found is None:\n",
    "        for article_id in root.findall('.//ArticleId'):\n",
    "            if article_id.get('IdType') == 'doi':\n",
    "                doi_found = article_id.text.strip()\n",
    "                break\n",
    "    \n",
    "    if language_check:\n",
    "        return doi_found\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doi.org/10.1073/pnas.2311865121\n",
      "https://doi.org/10.1073/pnas.2311241121\n",
      "https://doi.org/10.1073/pnas.2317563121\n",
      "https://doi.org/10.1073/pnas.2407437121\n"
     ]
    }
   ],
   "source": [
    "pm_ids = [38861610, 38838020, 38771875, 38814864]\n",
    "full_text_url = []\n",
    "\n",
    "for pm_id in pm_ids:\n",
    "    x = fetch_doi(pm_id)\n",
    "    url = f\"https://doi.org/{x}\"\n",
    "    print(url)\n",
    "    full_text_url.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted.\n",
      "Text extracted.\n",
      "Text extracted.\n",
      "No text extracted from https://doi.org/10.1073/pnas.2407437121\n"
     ]
    }
   ],
   "source": [
    "def get_full_text_table(full_url, j):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(full_url)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    text_elements = []\n",
    "\n",
    "    # Extract text from <div> elements with role=\"paragraph\" and header tags\n",
    "    for element in soup.find_all(['div', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        if element.name == 'div' and element.get('role') == 'paragraph':\n",
    "            text_elements.append(element.get_text())\n",
    "        elif element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "            text_elements.append(element.get_text())\n",
    "\n",
    "    # Combine all text elements into a single string\n",
    "    full_text = ' '.join(text_elements)\n",
    "\n",
    "    # removing unwanted text\n",
    "    unwanted_texts = [\n",
    "            \"DOI Not Found\"\n",
    "        ]\n",
    "    if any(unwanted in full_text for unwanted in unwanted_texts):\n",
    "        full_text = \"\"\n",
    "        #print(\"DOI Not Found\")\n",
    "\n",
    "    if full_text.strip():\n",
    "        # removing unwanted text\n",
    "        prefix = \"Featured Topics Articles By Topic Featured Topics Articles By Topic Featured Topic Articles By Topic ARTICLES AUTHORS Featured Topics Articles By Topic Featured Topics Articles By Topic Featured Topic Articles By Topic \"\n",
    "        if full_text.startswith(prefix):\n",
    "            full_text = full_text[len(prefix):]\n",
    "        truncation_point = full_text.find(\"Citation statements\")\n",
    "        if truncation_point != -1:\n",
    "            full_text = full_text[:truncation_point]\n",
    "        \n",
    "        directory = r'C:\\Users\\Ajay Kanna\\Desktop\\UGRC\\extract abstract\\Proceedings of the National Academy of Sciences of the United States of America\\full_text_stored'\n",
    "        output_file_path = os.path.join(directory, f'extracted_text_{j}.txt')\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "            print(\"Text extracted.\")\n",
    "            file.write(full_text)\n",
    "    else:\n",
    "        print(f\"No text extracted from {full_url}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "for j, url in enumerate(full_text_url, start=1):\n",
    "    if url:\n",
    "        get_full_text_table(url, j)\n",
    "    else:\n",
    "        print(\"can't extract: maybe not written in english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
